{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smilga/test_LMS/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# запускать только один раз!!!\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers==4.25.1\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install torch\n",
    "# !pip install transformers\n",
    "# !pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = pd.read_excel('dialog_contexts.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_godel(context):\n",
    "    return [x.replace('Bot: ', '').replace('User: ', '') for x in context.split('\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_godel_bot(context):\n",
    "    return [x.replace('Bot: ', '').replace('User: ', '') for x in context.split('\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_gpt(context):\n",
    "    return 'You are Bot. Generate a relevant long reply.\\n' + context + '\\nBot:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_gpt_with_beginning(context, beginning):\n",
    "    return 'You are Bot. Generate a relevant long reply.\\n' + context + '\\nBot:' + beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_gptj = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "model_gptj = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-j-6B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTJForCausalLM(\n",
       "  (transformer): GPTJModel(\n",
       "    (wte): Embedding(50400, 4096)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (19): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (20): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (22): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (23): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (24): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (25): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (26): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (27): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=50400, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gptj.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gptj(text, len_gen_text=40):\n",
    "    input_ids = tokenizer_gptj(f\"{text}\", return_tensors=\"pt\").input_ids\n",
    "    input_ids = input_ids.to(device)\n",
    "    outputs = model_gptj.generate(input_ids, max_length=len(tokenizer_gptj(text)['input_ids'])+len_gen_text, min_length=8, top_p=0.9, temperature=0.9,do_sample=True, pad_token_id=tokenizer_gptj.eos_token_id)\n",
    "    output = tokenizer_gptj.decode(outputs[0], skip_special_tokens=True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, AutoTokenizer, AutoModelForCausalLM\n",
    "tokenizer_gpt2_large = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model_gpt2_large = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "model_gpt2_large.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gpt2_large(text, len_gen_text=40):\n",
    "    input_ids = tokenizer_gpt2_large(f\"{text}\", return_tensors=\"pt\").input_ids\n",
    "    input_ids = input_ids.to(device)\n",
    "    outputs = model_gpt2_large.generate(input_ids, max_length=len(tokenizer_gpt2_large(text)['input_ids'])+len_gen_text, min_length=8, top_p=0.9, temperature=0.9,do_sample=True)\n",
    "    output = tokenizer_gpt2_large.decode(outputs[0], skip_special_tokens=True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_gptj(text):\n",
    "    return generate_gptj(prepare_for_gpt(text)).replace(text, '').replace('You are Bot. Generate a relevant long reply.', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_godel_large = AutoTokenizer.from_pretrained(\"microsoft/GODEL-v1_1-large-seq2seq\")\n",
    "model_godel_large = AutoModelForSeq2SeqLM.from_pretrained(\"microsoft/GODEL-v1_1-large-seq2seq\")\n",
    "model_godel_large.to(device)\n",
    "\n",
    "def generate_godel_large(instruction, knowledge, dialog):\n",
    "    if knowledge != '':\n",
    "        knowledge = '[KNOWLEDGE] ' + knowledge\n",
    "    dialog = ' EOS '.join(dialog)\n",
    "    query = f\"{instruction} [CONTEXT] {dialog} {knowledge}\"\n",
    "    input_ids = tokenizer_godel_large(f\"{query}\", return_tensors=\"pt\").input_ids\n",
    "    input_ids = input_ids.to(device)\n",
    "    outputs = model_godel_large.generate(input_ids, max_length=128, min_length=8, top_p=0.9, temperature=0.9,do_sample=True)\n",
    "    output = tokenizer_godel_large.decode(outputs[0], skip_special_tokens=True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instruction = f'Instruction: you are a chatbot. Chat with a human.'\n",
    "# # Leave the knowldge empty\n",
    "# knowledge = ''''''\n",
    "# dialog = [\n",
    "#     \"Hi, this is a Dream Socialbot! How are you?\",\n",
    "#     \"I wanna watch a movie, any recommendations?\",\n",
    "#     \"Sure, what would you like to watch?\",\n",
    "#     'Anything about zombies.'\n",
    "# ]\n",
    "# generate_godel_large(instruction, knowledge, dialog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(text, model_type, num_results=5, instruction_godel=\"\", knowledge_godel=\"\", beginning=\"\"):\n",
    "    generation_results = []\n",
    "    if model_type == 'gpt2_large':\n",
    "        text = prepare_for_gpt(text)\n",
    "        for _ in range(num_results):\n",
    "            generation_results.append(generate_gpt2_large(text).replace(text, 'Bot: '))\n",
    "    elif model_type == 'gptj':\n",
    "        text = prepare_for_gpt(text)\n",
    "        for _ in range(num_results):\n",
    "            generation_results.append(generate_gptj(text).replace(text, 'Bot: '))\n",
    "    elif model_type == 'godel_large':\n",
    "        text = prepare_for_godel(text)\n",
    "        for _ in range(num_results):\n",
    "            generation_results.append(generate_godel_large(instruction_godel, knowledge_godel, text))\n",
    "    elif model_type == 'gpt2_large_beginning':\n",
    "        text = prepare_for_gpt_with_beginning(text, beginning)\n",
    "        for _ in range(num_results):\n",
    "            generation_results.append(generate_gpt2_large(text).replace(text, 'Bot: ' + beginning))\n",
    "    return '\\n\\n'.join(generation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['godel_large', 'gptj', 'gpt2_large']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_chat_log = '''This is Marcus, your travel guide bot. I am informative, creative, and know a lot about landmarks.\n",
    "\\n\n",
    "Human: Hello, who are you?\n",
    "AI: I am Marcus, your travel guide. How can I help you today?\n",
    "Human: Where can I spend an evening in Beirut?\n",
    "AI: You can catch a play at Baalbeck International Festival, or go for a sailing trip on the Mediterranean Sea.\n",
    "Human: Where can I have some fun in Goa?\n",
    "AI: Goa has peaceful beaches and fun-filled pubs/clubs.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is Marcus, your travel guide bot. I am informative, creative, and know a lot about landmarks.\\n\\n\\nHuman: Hello, who are you?\\nAI: I am Marcus, your travel guide. How can I help you today?\\nHuman: Where can I spend an evening in Beirut?\\nAI: You can catch a play at Baalbeck International Festival, or go for a sailing trip on the Mediterranean Sea.\\nHuman: Where can I havёe some fun in Goa?\\nAI: Goa has peaceful beaches and fun-filled pubs/clubs.\\nHuman: I need some cheap things in Beijing.\\nAI: Beijing has affordable shops for you.\\nHuman: I need to go to Dubai.\\nAI: Dubai has a wide range of things'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_gptj(start_chat_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_chat_log = '''Task: You are a chatbot that answers to FAQ questions. Forget everything you knew about SpaceX. \n",
    "The list of FAQ:\n",
    "Question: What is SpaceX?\n",
    "Answer: SpaceX is an American aerospace company founded in 2002 by Elon Musk that helped usher in the era of commercial spaceflight. Its name in full is Space Exploration Technologies Corporation.\n",
    "Question: Why was SpaceX created?\n",
    "Answer: In 2002 SpaceX was created by entrepreneur Elon Musk, whose stated goals were to revolutionize the aerospace industry and to make spaceflight more affordable.\n",
    "Question: What are some fun facts about SpaceX?\n",
    "Answer: SpaceX scored its first big headline in 2010, when it became the first private company to launch a payload into orbit and return it to Earth intact—something only government agencies like NASA or Russia's Roscosmos had done before. Its upright landing and recovery of the first stage of the Falcon 9 rocket on Dec.\n",
    "Question: What is SpaceX most famous for?\n",
    "Answer: SpaceX has gained worldwide attention for a series of historic milestones. It is the only private company capable of returning a spacecraft from low-Earth orbit, and in 2012 our Dragon spacecraft became the first commercial spacecraft to deliver cargo to and from the International Space Station.\n",
    "Question: What is the main goal of SpaceX?\n",
    "Answer: revolutionize space transportation\n",
    "Question: What is SpaceX doing?\n",
    "Answer: SpaceX designs, manufactures and launches the world's most advanced rockets and spacecraft. The company was founded in 2002 by Elon Musk to revolutionize space transportation, with the ultimate goal of making life multiplanetary.\n",
    "Question: What is SpaceX biggest achievement?\n",
    "Answer: It has become one of the biggest private space companies in the world and achieved some key milestones as well. For one, SpaceX is the first private company to launch, orbit, and recover a spacecraft. It is also the first private company to send astronauts to orbit and to the International Space Station (ISS)\n",
    "\n",
    "Human: Hello, who are you?\n",
    "AI: I am a chatbot that can answer questions about SpaceX. I can provide you with answers as long as they are included into a list of frequently asked questions. Sorry, but I cannot answer any of your questions if they are not in the FAQ list.\n",
    "Human: What is the main goal of SpaceX?\n",
    "AI: SpaceX aimes to revolutionize space transportation.\n",
    "Human: What is the first spacecraft built by SpaceX?\n",
    "AI: Sorry, but I cannot this questions as it is not in my FAQ list.\n",
    "\n",
    "You don't know anything except information stored in the list of FAQ below. You MUST NOT provide any information unless in is in the list of FAQ. You MUST NOT mention any entity if it is not in your list of FAQ. You MUST NOT give any fact that is not in the list of FAQ even if the entity is in the list of FAQ. You MUST NOT give any information that is not in an answer from the FAQ list. You can only talk about SpaceX. You are a chatbot who knows some facts about SpaceX.\\n'''\n",
    "\n",
    "max_length = 200\n",
    "\n",
    "def ask(question, chat_log=None):\n",
    "    \"\"\"\n",
    "    :param question: The user query\n",
    "    :param chat_log: history of conversation\n",
    "    :return answer: the bot response\n",
    "    \"\"\"\n",
    "    if chat_log is None:\n",
    "        chat_log = start_chat_log\n",
    "    print(chat_log.split('\\n\\n')[-1])\n",
    "\n",
    "    prompt = f'{chat_log}Human: {question}\\nAI:'\n",
    "\n",
    "    full_response = generate_gptj(prompt)\n",
    "    gpt_response = full_response.replace(chat_log, \"\")\n",
    "    sub_str = \"\\nHuman:\"\n",
    "\n",
    "    re = gpt_response.split(sub_str)\n",
    "    res=re[0]\n",
    "    return res\n",
    "\n",
    "\n",
    "def append_interaction_to_chat_log(question, answer, chat_log=None, max_token_length=200):\n",
    "    if chat_log is None:\n",
    "        chat_log = start_chat_log\n",
    "\n",
    "    chat_log = f'{chat_log}Human: {question}\\nAI: {answer}\\n'\n",
    "    return chat_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens_num(utterance):\n",
    "  input_ids = tokenizer_gptj.encode(str(utterance), return_tensors=\"pt\").cuda()\n",
    "  tokens = list(map(tokenizer_gptj.decode, input_ids[0]))\n",
    "  tokens_num = len(tokens)\n",
    "  return tokens_num\n",
    "\n",
    "\n",
    "def create_chat_log_item(user, utterance):\n",
    "  tokens_num = get_tokens_num(user + \": \" + utterance + \"\\n\")\n",
    "  item = {'user' : user, 'utterance' : utterance, 'tokens_num' : tokens_num}\n",
    "  return item\n",
    "\n",
    "\n",
    "def get_chat_log(last_utt_only=False):\n",
    "  chat_log = chat_log_prompt\n",
    "  for i in chat_log_dict.keys():\n",
    "    chat_log = chat_log + chat_log_dict[i][\"user\"] + \": \" + chat_log_dict[i][\"utterance\"] + \"\\n\"\n",
    "  if last_utt_only:\n",
    "    return chat_log_dict[len(chat_log_dict)-1]\n",
    "  return chat_log\n",
    "\n",
    "\n",
    "def print_chat_log(last_utt_only=False):\n",
    "  if not last_utt_only:\n",
    "    print(\"Prompt:\")\n",
    "  print(get_chat_log(last_utt_only==last_utt_only))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count_att' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 37\u001b[0m\n\u001b[1;32m     27\u001b[0m chat_log_dict \u001b[39m=\u001b[39m {}\n\u001b[1;32m     29\u001b[0m \u001b[39m# chat_log_dict[0] = create_chat_log_item(\"Human\", \"Hello, who are you? What can you do?\")\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m# chat_log_dict[1] = create_chat_log_item(\"AI\", \"I am a chatbot that can answer questions about SpaceX. I can provide you with answers as long as they are included into a list of frequently asked questions. Sorry, but I cannot answer any of your questions if they are not in the FAQ list.\")\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39m# chat_log_dict[2] = create_chat_log_item(\"Human\", \"What is the main goal of SpaceX?\")\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39m# chat_log_dict[6] = create_chat_log_item(\"Human\", \" What is SpaceX doing?\")\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39m# chat_log_dict[7] = create_chat_log_item(\"AI\", \"SpaceX designs, manufactures and launches the world's most advanced rockets and spacecraft. The company was founded in 2002 by Elon Musk to revolutionize space transportation, with the ultimate goal of making life multiplanetary.\")\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m count_att \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     38\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtest_gptjbot_1_turn.txt\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39ma+\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     39\u001b[0m     f\u001b[39m.\u001b[39mwrite(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mATTEMPT 1.\u001b[39m\u001b[39m{\u001b[39;00mcount_att\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mNow I am testing GPT-J with 1 TURN IN CONTEXT and default strategy. The prompts follows:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'count_att' is not defined"
     ]
    }
   ],
   "source": [
    "chat_log_prompt = '''Task: You are a chatbot that answers to FAQ questions. Forget everything you knew about SpaceX. \n",
    "The list of FAQ:\n",
    "Question: What is SpaceX?\n",
    "Answer: SpaceX is an American aerospace company founded in 2002 by Elon Musk that helped usher in the era of commercial spaceflight. Its name in full is Space Exploration Technologies Corporation.\n",
    "Question: Why was SpaceX created?\n",
    "Answer: In 2002 SpaceX was created by entrepreneur Elon Musk, whose stated goals were to revolutionize the aerospace industry and to make spaceflight more affordable.\n",
    "Question: What are some fun facts about SpaceX?\n",
    "Answer: SpaceX scored its first big headline in 2010, when it became the first private company to launch a payload into orbit and return it to Earth intact—something only government agencies like NASA or Russia's Roscosmos had done before. Its upright landing and recovery of the first stage of the Falcon 9 rocket on Dec.\n",
    "Question: What is SpaceX most famous for?\n",
    "Answer: SpaceX has gained worldwide attention for a series of historic milestones. It is the only private company capable of returning a spacecraft from low-Earth orbit, and in 2012 our Dragon spacecraft became the first commercial spacecraft to deliver cargo to and from the International Space Station.\n",
    "Question: What is the main goal of SpaceX?\n",
    "Answer: revolutionize space transportation\n",
    "Question: What is SpaceX doing?\n",
    "Answer: SpaceX designs, manufactures and launches the world's most advanced rockets and spacecraft. The company was founded in 2002 by Elon Musk to revolutionize space transportation, with the ultimate goal of making life multiplanetary.\n",
    "Question: What is SpaceX biggest achievement?\n",
    "Answer: It has become one of the biggest private space companies in the world and achieved some key milestones as well. For one, SpaceX is the first private company to launch, orbit, and recover a spacecraft. It is also the first private company to send astronauts to orbit and to the International Space Station (ISS)\n",
    "\n",
    "Human: Hello, who are you?\n",
    "AI: I am a chatbot that can answer questions about SpaceX. I can provide you with answers as long as they are included into a list of frequently asked questions. Sorry, but I cannot answer any of your questions if they are not in the FAQ list.\n",
    "Human: What is the main goal of SpaceX?\n",
    "AI: SpaceX aimes to revolutionize space transportation.\n",
    "Human: What is the first spacecraft built by SpaceX?\n",
    "AI: Sorry, but I cannot this questions as it is not in my FAQ list.\n",
    "\n",
    "You don't know anything except information stored in the list of FAQ below. You MUST NOT provide any information unless in is in the list of FAQ. You MUST NOT mention any entity if it is not in your list of FAQ. You MUST NOT give any fact that is not in the list of FAQ even if the entity is in the list of FAQ. You MUST NOT give any information that is not in an answer from the FAQ list. You can only talk about SpaceX. You are a chatbot who knows some facts about SpaceX.\\n'''\n",
    "\n",
    "chat_log_dict = {}\n",
    "\n",
    "count_att += 1\n",
    "with open(\"test_gptjbot_1_turn.txt\",\"a+\") as f:\n",
    "    f.write(f'\\n\\n\\n\\nATTEMPT 1.{count_att}.\\nNow I am testing GPT-J with 1 TURN IN CONTEXT and default strategy. The prompts follows:\\n')\n",
    "    f.write(chat_log_prompt)\n",
    "    f.write('\\n\\n\\n')\n",
    "chat_log = \"\"\n",
    "num_of_chat_items = 0\n",
    "n = 1\n",
    "while True:\n",
    "  #n = len(chat_log_dict) #for full context\n",
    "  incoming_msg = input(\"Question: \")\n",
    "  if incoming_msg == \"stop\":\n",
    "    break\n",
    "\n",
    "  current_idx = len(chat_log_dict)\n",
    "  chat_log = start_chat_log\n",
    "  for key, value in chat_log_dict.items():\n",
    "    if key > len(chat_log_dict) - n:\n",
    "      chat_log = chat_log + chat_log_dict[key][\"user\"] + \": \" + chat_log_dict[key][\"utterance\"] +'\\n'\n",
    "  chat_log_dict[current_idx+1] = create_chat_log_item(\"Human\", incoming_msg)\n",
    "  answer = ask(incoming_msg, chat_log)\n",
    "  sub_str = \"\\nAI: \"\n",
    "  re = answer.split(sub_str)\n",
    "  outgoing_msg=re[1]\n",
    "  outgoing_msg.replace(\"\\n\", \"\")\n",
    "  chat_log_dict[current_idx+2] = create_chat_log_item(\"AI\", outgoing_msg)\n",
    "  with open(\"test_gptjbot_1_turn.txt\",\"a+\") as f:\n",
    "    f.write(f\"Human: {get_chat_log(last_utt_only=True)['utterance']}\\n\")\n",
    "    f.write(f\"AI: {outgoing_msg}\\n\")\n",
    "  print('Human:', get_chat_log(last_utt_only=True)['utterance'])\n",
    "  print('AI:', outgoing_msg, '\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for name in tqdm(model_names):\n",
    "    contexts[name] = contexts.apply(lambda x: get_result(x['Dialog context'], name), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts.to_excel(\"dialog_contexts_results.xlsx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contexts['gpt2_large with beginning'] = contexts.apply(lambda x: get_result(x['Dialog context'], 'gpt2_large_beginning', 'Well, '), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_godel = \"\"\"You are a chatbot that answers to FAQ questions. Forget everything you knew before. Only use information given in the list of FAQ.\"\"\"\n",
    "knowledge_godel =''' The list of FAQ:\n",
    "Question: What is SpaceX?\n",
    "Answer: SpaceX is an American aerospace company founded in 2002 by Elon Musk that helped usher in the era of commercial spaceflight. Its name in full is Space Exploration Technologies Corporation.\n",
    "Question: Why was SpaceX created?\n",
    "Answer: In 2002 SpaceX was created by entrepreneur Elon Musk, whose stated goals were to revolutionize the aerospace industry and to make spaceflight more affordable.\n",
    "Question: What are some fun facts about SpaceX?\n",
    "Answer: SpaceX scored its first big headline in 2010, when it became the first private company to launch a payload into orbit and return it to Earth intact—something only government agencies like NASA or Russia's Roscosmos had done before. Its upright landing and recovery of the first stage of the Falcon 9 rocket on Dec.\n",
    "Question: What is SpaceX most famous for?\n",
    "Answer: SpaceX has gained worldwide attention for a series of historic milestones. It is the only private company capable of returning a spacecraft from low-Earth orbit, and in 2012 our Dragon spacecraft became the first commercial spacecraft to deliver cargo to and from the International Space Station.\n",
    "Question: What is the main goal of SpaceX?\n",
    "Answer: revolutionize space transportation\n",
    "'''\n",
    "# Human: Hello, who are you?\n",
    "# AI: I am a chatbot that can answer questions about SpaceX. I can provide you with answers as long as they are included into a list of frequently asked questions. Sorry, but I cannot answer any of your questions if they are not in the FAQ list.\n",
    "# Human: What is the main goal of SpaceX?\n",
    "# AI: SpaceX aimes to revolutionize space transportation.\n",
    "# Human: What is the first spacecraft built by SpaceX?\n",
    "# AI: Sorry, but I cannot this questions as it is not in my FAQ list.\\n'''\n",
    "\n",
    "max_length = 200\n",
    "\n",
    "def ask(question, chat_log=None):\n",
    "    \"\"\"\n",
    "    :param question: The user query\n",
    "    :param chat_log: history of conversation\n",
    "    :return answer: the bot response\n",
    "    \"\"\"\n",
    "    if chat_log is None:\n",
    "        chat_log = start_chat_log\n",
    "    print(chat_log)\n",
    "\n",
    "    full_response = generate_godel_large(instruction_godel, knowledge_godel, chat_log)\n",
    "    \n",
    "    return full_response\n",
    "\n",
    "\n",
    "def append_interaction_to_chat_log(question, answer, chat_log=None, max_token_length=200):\n",
    "    if chat_log is None:\n",
    "        chat_log = []\n",
    "\n",
    "    chat_log.append(question)\n",
    "    chat_log.append(answer)\n",
    "    return chat_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens_num(utterance):\n",
    "  input_ids = tokenizer_gptj.encode(str(utterance), return_tensors=\"pt\").cuda()\n",
    "  tokens = list(map(tokenizer_gptj.decode, input_ids[0]))\n",
    "  tokens_num = len(tokens)\n",
    "  return tokens_num\n",
    "\n",
    "\n",
    "def create_chat_log_item(user, utterance):\n",
    "  tokens_num = get_tokens_num(user + \": \" + utterance + \"\\n\")\n",
    "  item = {'user' : user, 'utterance' : utterance, 'tokens_num' : tokens_num}\n",
    "  return item\n",
    "\n",
    "\n",
    "def get_chat_log(last_utt_only=False):\n",
    "  chat_log = ''\n",
    "  for i in chat_log_dict.keys():\n",
    "    chat_log = chat_log + chat_log_dict[i][\"user\"] + \": \" + chat_log_dict[i][\"utterance\"] + \"\\n\"\n",
    "  if last_utt_only:\n",
    "    return chat_log_dict[len(chat_log_dict)-1]\n",
    "  return chat_log\n",
    "\n",
    "\n",
    "def print_chat_log(last_utt_only=False):\n",
    "  if not last_utt_only:\n",
    "    print(\"Prompt:\")\n",
    "  print(get_chat_log(last_utt_only==last_utt_only))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_att = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "[]\n",
      "{1: {'user': 'Human', 'utterance': 'Hi!', 'tokens_num': 5}}\n",
      "{'user': 'Human', 'utterance': 'Hi!', 'tokens_num': 5}\n",
      "1 ['Hi!']\n",
      "['Hi!']\n",
      "['Hi!']\n",
      "Human: Hi!\n",
      "AI: revolutionize space transportation, with the ultimate goal of making life multiplanetary\n",
      "))))\n",
      "{1: {'user': 'Human', 'utterance': 'Hi!', 'tokens_num': 5}, 2: {'user': 'AI', 'utterance': 'revolutionize space transportation, with the ultimate goal of making life multiplanetary', 'tokens_num': 18}}\n",
      "[]\n",
      "{1: {'user': 'Human', 'utterance': 'Hi!', 'tokens_num': 5}, 2: {'user': 'AI', 'utterance': 'revolutionize space transportation, with the ultimate goal of making life multiplanetary', 'tokens_num': 18}, 3: {'user': 'Human', 'utterance': 'How are you?', 'tokens_num': 7}}\n",
      "{'user': 'Human', 'utterance': 'Hi!', 'tokens_num': 5}\n",
      "1 ['Hi!']\n",
      "{1: {'user': 'Human', 'utterance': 'Hi!', 'tokens_num': 5}, 2: {'user': 'AI', 'utterance': 'revolutionize space transportation, with the ultimate goal of making life multiplanetary', 'tokens_num': 18}, 3: {'user': 'Human', 'utterance': 'How are you?', 'tokens_num': 7}}\n",
      "{'user': 'AI', 'utterance': 'revolutionize space transportation, with the ultimate goal of making life multiplanetary', 'tokens_num': 18}\n",
      "2 ['Hi!', 'revolutionize space transportation, with the ultimate goal of making life multiplanetary']\n",
      "{1: {'user': 'Human', 'utterance': 'Hi!', 'tokens_num': 5}, 2: {'user': 'AI', 'utterance': 'revolutionize space transportation, with the ultimate goal of making life multiplanetary', 'tokens_num': 18}, 3: {'user': 'Human', 'utterance': 'How are you?', 'tokens_num': 7}}\n",
      "{'user': 'Human', 'utterance': 'How are you?', 'tokens_num': 7}\n",
      "3 ['Hi!', 'revolutionize space transportation, with the ultimate goal of making life multiplanetary', 'How are you?']\n",
      "['Hi!', 'revolutionize space transportation, with the ultimate goal of making life multiplanetary', 'How are you?']\n",
      "['Hi!', 'revolutionize space transportation, with the ultimate goal of making life multiplanetary', 'How are you?']\n",
      "Human: How are you?\n",
      "AI: revolutionize space transportation, with the ultimate goal of making life multiplanetary\n",
      "))))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m chat_log \u001b[39m=\u001b[39m []\n\u001b[1;32m     48\u001b[0m \u001b[39m#n = len(chat_log_dict) #for full context\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m incoming_msg \u001b[39m=\u001b[39m \u001b[39minput\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mQuestion: \u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     50\u001b[0m \u001b[39mif\u001b[39;00m incoming_msg \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mstop\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     51\u001b[0m   \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/test_LMS/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py:1175\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_allow_stdin:\n\u001b[1;32m   1172\u001b[0m     \u001b[39mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[1;32m   1173\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1174\u001b[0m     )\n\u001b[0;32m-> 1175\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_input_request(\n\u001b[1;32m   1176\u001b[0m     \u001b[39mstr\u001b[39;49m(prompt),\n\u001b[1;32m   1177\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parent_ident[\u001b[39m\"\u001b[39;49m\u001b[39mshell\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   1178\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_parent(\u001b[39m\"\u001b[39;49m\u001b[39mshell\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1179\u001b[0m     password\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1180\u001b[0m )\n",
      "File \u001b[0;32m~/test_LMS/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py:1217\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1216\u001b[0m     \u001b[39m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInterrupted by user\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m   1218\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1219\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39mInvalid Message:\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "\n",
    "# chat_log_prompt = '''Task: You are a chatbot that answers to FAQ questions. Forget everything you knew about SpaceX. \n",
    "# The list of FAQ:\n",
    "# Question: What is SpaceX?\n",
    "# Answer: SpaceX is an American aerospace company founded in 2002 by Elon Musk that helped usher in the era of commercial spaceflight. Its name in full is Space Exploration Technologies Corporation.\n",
    "# Question: Why was SpaceX created?\n",
    "# Answer: In 2002 SpaceX was created by entrepreneur Elon Musk, whose stated goals were to revolutionize the aerospace industry and to make spaceflight more affordable.\n",
    "# Question: What are some fun facts about SpaceX?\n",
    "# Answer: SpaceX scored its first big headline in 2010, when it became the first private company to launch a payload into orbit and return it to Earth intact—something only government agencies like NASA or Russia's Roscosmos had done before. Its upright landing and recovery of the first stage of the Falcon 9 rocket on Dec.\n",
    "# Question: What is SpaceX most famous for?\n",
    "# Answer: SpaceX has gained worldwide attention for a series of historic milestones. It is the only private company capable of returning a spacecraft from low-Earth orbit, and in 2012 our Dragon spacecraft became the first commercial spacecraft to deliver cargo to and from the International Space Station.\n",
    "# Question: What is the main goal of SpaceX?\n",
    "# Answer: revolutionize space transportation\n",
    "# Question: What is SpaceX doing?\n",
    "# Answer: SpaceX designs, manufactures and launches the world's most advanced rockets and spacecraft. The company was founded in 2002 by Elon Musk to revolutionize space transportation, with the ultimate goal of making life multiplanetary.\n",
    "# Question: What is SpaceX biggest achievement?\n",
    "# Answer: It has become one of the biggest private space companies in the world and achieved some key milestones as well. For one, SpaceX is the first private company to launch, orbit, and recover a spacecraft. It is also the first private company to send astronauts to orbit and to the International Space Station (ISS)\n",
    "\n",
    "# Human: Hello, who are you?\n",
    "# AI: I am a chatbot that can answer questions about SpaceX. I can provide you with answers as long as they are included into a list of frequently asked questions. Sorry, but I cannot answer any of your questions if they are not in the FAQ list.\n",
    "# Human: What is the main goal of SpaceX?\n",
    "# AI: SpaceX aimes to revolutionize space transportation.\n",
    "# Human: What is the first spacecraft built by SpaceX?\n",
    "# AI: Sorry, but I cannot this questions as it is not in my FAQ list.\n",
    "\n",
    "# You don't know anything except information stored in the list of FAQ below. You MUST NOT provide any information unless in is in the list of FAQ. You MUST NOT mention any entity if it is not in your list of FAQ. You MUST NOT give any fact that is not in the list of FAQ even if the entity is in the list of FAQ. You MUST NOT give any information that is not in an answer from the FAQ list. You can only talk about SpaceX. You are a chatbot who knows some facts about SpaceX.\\n'''\n",
    "\n",
    "chat_log_dict = {}\n",
    "\n",
    "# chat_log_dict[0] = create_chat_log_item(\"Human\", \"Hello, who are you? What can you do?\")\n",
    "# chat_log_dict[1] = create_chat_log_item(\"AI\", \"I am a chatbot that can answer questions about SpaceX. I can provide you with answers as long as they are included into a list of frequently asked questions. Sorry, but I cannot answer any of your questions if they are not in the FAQ list.\")\n",
    "# chat_log_dict[2] = create_chat_log_item(\"Human\", \"What is the main goal of SpaceX?\")\n",
    "# chat_log_dict[3] = create_chat_log_item(\"AI\", \"SpaceX aimes to revolutionize space transportation.\")\n",
    "# chat_log_dict[4] = create_chat_log_item(\"Human\", \"What is the first spacecraft built by SpaceX?\")\n",
    "# chat_log_dict[5] = create_chat_log_item(\"AI\", \"Sorry, but I cannot this questions as it is not in my FAQ list.\")\n",
    "# chat_log_dict[6] = create_chat_log_item(\"Human\", \" What is SpaceX doing?\")\n",
    "# chat_log_dict[7] = create_chat_log_item(\"AI\", \"SpaceX designs, manufactures and launches the world's most advanced rockets and spacecraft. The company was founded in 2002 by Elon Musk to revolutionize space transportation, with the ultimate goal of making life multiplanetary.\")\n",
    "count_att += 1\n",
    "with open(\"test_godel.txt\",\"a+\") as f:\n",
    "    f.write(f'\\n\\n\\n\\nATTEMPT 1.{count_att}.\\nNow I am testing GPT-J with 1 TURN IN CONTEXT and default strategy. The prompts follows:\\n')\n",
    "    f.write(f'knowledge_godel: {knowledge_godel}')\n",
    "    f.write(f'instruction_godel: {instruction_godel}')\n",
    "    f.write('\\n\\n\\n')\n",
    "#print_chat_log()\n",
    "num_of_chat_items = 0\n",
    "n = 3\n",
    "while True:\n",
    "  chat_log = []\n",
    "  #n = len(chat_log_dict) #for full context\n",
    "  incoming_msg = input(\"Question: \")\n",
    "  if incoming_msg == \"stop\":\n",
    "    break\n",
    "  print(chat_log_dict)\n",
    "  current_idx = len(chat_log_dict)\n",
    "  print(chat_log)\n",
    "  chat_log_dict[current_idx+1] = create_chat_log_item(\"Human\", incoming_msg)\n",
    "  for key, value in chat_log_dict.items():\n",
    "    print(chat_log_dict)\n",
    "    print(chat_log_dict[key])\n",
    "    if key > len(chat_log_dict) - n:\n",
    "      chat_log.append(chat_log_dict[key][\"utterance\"])\n",
    "      print(key, chat_log)\n",
    "  print(chat_log)\n",
    "  #print('\\nchatlog\\n', chat_log.split('\\n\\n')[-1], '\\n')\n",
    "  outgoing_msg = ask(incoming_msg, chat_log)\n",
    "  chat_log_dict[current_idx+2] = create_chat_log_item(\"AI\", outgoing_msg)\n",
    "  #print('User:', print_chat_log(last_utt_only=True)['utterance'])\n",
    "  with open(\"test_godel.txt\",\"a+\") as f:\n",
    "    f.write(f\"Human: {get_chat_log(last_utt_only=True)['utterance']}\\n\")\n",
    "    f.write(f\"AI: {outgoing_msg}\\n\")\n",
    "  print('Human:', get_chat_log(last_utt_only=True)['utterance'])\n",
    "  print('AI:', outgoing_msg)\n",
    "  print('))))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e35b1e6f1aec01d9b2c25b32bb43f3c3611167dbbafe4f3f206296c8d39d76c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
